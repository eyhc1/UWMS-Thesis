\chapter{Discussion}

% \section{Hardware Precision}

% The current FPGA-based control system for quantum laser control successfully demonstrates proof-of-concept functionality, serving as a foundational step toward its broader application. However, several areas require refinement to enhance its accuracy and overall performance. One critical issue arises during pulse channel testing against the corresponding software module. Consistent discrepancies are observed between the theoretical and actual values. These errors are predominantly caused by the hardware's rounding mechanism.

% From \autoref{fig:block_diagram}, the data and address inputs and outputs of the waveform table memory must be floored to the nearest integer to ensure proper functionality of the hardware. While this method allows the system to work, it introduces errors that affect the precision of the laser control. The primary reason for these inaccuracies lies in the limitations of the current rounding mechanism, which discards valuable fractional information during the flooring process. To address this, an improved rounding mechanism should be explored. For example, implementing rounding techniques that minimize truncation errors, such as midpoint rounding or adaptive precision strategies, could significantly reduce the discrepancies.



% Transitioning to C firmware offers several advantages. First, it reduces latency by capitalizing on a faster data interface, which is crucial for time-sensitive quantum laser control operations. Second, integrating the firmware within the FPGA's processing system enhances system stability and simplifies debugging by consolidating control functions into one environment. Third, this approach creates a more straightforward pathway to real-time adjustments, which is essential when fine-tuning experimental conditions in quantum applications.

% \section{Limited Pulse Shaping and Precision}

% Current efforts illustrate how waveforms are generated using predefined tables scaled by predetermined values. This approach requires that the user first computes the waveform externally and then loads the calculated values into the system. Since generating a complete waveform involves several samples, the system must perform multiple write operations to the waveform table memory. This method reflects a balance between simplicity and resource constraints. Using predefined tables minimizes the need for complex on-chip logic but limits resolution with its 16-bit integer representation. Such limitations can be critical when precision is essential, as even slight quantization errors can distort the final waveform. This design embodies common trade-offs in FPGA-based systems. Predefined tables reduce on-chip complexity and simplify resource management; however, they inherently limit precision by relying on fixed-point values.

% Alternatively, a dynamic waveform generation may be implemented as a future enhancement. Although not implemented in the current design, it promises to address the accuracy issues by allowing the hardware to compute the waveform in real time based solely on essential parameters. Under this proposed scheme, a user would only need to supply mathematical parameters—such as amplitude, frequency, and phase—rather than detailed sample values. This would minimize data transfer overhead and reduce quantization errors, leading to a waveform that more closely adheres to its theoretical definition. The existing method favors ease of implementation, while the dynamic generation proposal offers increased flexibility and accuracy.

\section{Hardware Precision}

The current FPGA-based control system for quantum laser control demonstrates proof-of-concept functionality and lays a foundation for future applications. However, test results reveal consistent discrepancies between theoretical and measured values. These errors stem primarily from the rounding mechanism. \autoref{fig:block_diagram} indicates that data and address inputs in the waveform table memory are floored to the nearest integer, which discards important fractional components and limits resolution.

Waveforms are generated from predefined tables that are externally computed and then loaded into the system. This method simplifies on-chip logic and resource management by avoiding complex dynamic computations. However, using a fixed 16-bit integer representation introduces quantization errors when multiple write operations produce a complete waveform. The resulting trade-off between simplicity and precision underscores the limitations of the current design. To improve accuracy, enhanced rounding methods—such as midpoint rounding or adaptive precision schemes—could reduce truncation errors. A shift toward dynamic waveform generation, where only key parameters (amplitude, frequency, phase) are provided, may further minimize data transfer overhead and yield waveforms that better match their theoretical definitions.

\section{Hardware Error Handling}

The system utilizes a basic error detection framework that effectively identifies invalid parameters. When an error occurs, the system sets a status flag for the controlling processor to read. However, it relies on a passive notification system rather than active error recovery. This approach depends entirely on a dedicated software interface to resolve issues, which can lead to complications if the software is not properly implemented or if parameter conversions fail.

For instance, the pulse channel's definition memory assumes that waveform parameters are provided in a consecutive, continuously incrementing order. There is no built-in mechanism to verify or correct such an order. The module directly maps the provided address to the memory. This design decision exposes the system to potential data inconsistencies when parameters are not correctly sequenced. Future development should introduce a mechanism to enforce cumulative writes of pulse parameters. 

Additionally, although allowing users to write to any memory location increases flexibility, it also raises the risk of overlapping writes. If memory address management is not tightly controlled, the chance of overriding existing data becomes significant. Addressing this vulnerability is essential to safeguard the system's stability and reliability.

% Subjected for removal if alternate firmware implemented
\section{Interface Latency}
% TODO: this is only the idea for new implementation... will get modified a lot after the new interface is done
Many user-level interfaces are implemented in Python on a separate PC, requiring frequent serial writes to the hardware system. Each UART serial write transmits only 8 bits of data from the host to the FPGA. This limited throughput results in extended read and write times. Tests have shown that reading the entire waveform memory takes three to four seconds on average. Such delays become a significant bottleneck, especially when multiple memory accesses occur during operation.

To mitigate this issue, sophisticated C firmware could replace much of Python's functionality. This firmware would reside on Xilinx's processing system, fully leveraging Zynq's high-speed AXI interface to accelerate data transfers. Instead of relying on Python functions to relay user parameters, the processing system would accept input directly from a command-line interface. Users could manually type parameters or design scripts to automate their entry.